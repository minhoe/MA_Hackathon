{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifiers for testing #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dninb/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/dninb/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn import cross_validation, metrics, grid_search, linear_model, svm\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_digits\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "n_fold = 5\n",
    "\n",
    "# Parameters\n",
    "lr_param = {'C':[0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.5, 1, 5, 10],\n",
    "           'tol' : [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10]}\n",
    "# lr_param = {'C':[0.01],\n",
    "#            'tol' : [1e-6]}\n",
    "lr_results = pd.DataFrame(np.empty((0,4), float), columns=['c', 'tol', 'AUROC', 'f1'])\n",
    "\n",
    "\n",
    "# Evaluation metrics\n",
    "def gini(list_of_values):\n",
    "  sorted_list = sorted(list(list_of_values))\n",
    "  height, area = 0, 0\n",
    "  for value in sorted_list:\n",
    "    height += value\n",
    "    area += height - value / 2.\n",
    "  fair_area = height * len(list_of_values) / 2\n",
    "  return (fair_area - area) / fair_area\n",
    "  \n",
    "def normalized_gini(y_pred, y):\n",
    "    normalized_gini = gini(y_pred)/gini(y)\n",
    "    return normalized_gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "# UCI Datasets \n",
    "iris_data   = load_iris()\n",
    "digits_data = load_digits()\n",
    "print(iris_data.data.shape)\n",
    "print(digits_data.data.shape)\n",
    "\n",
    "iris_X = iris_data.data\n",
    "iris_Y = iris_data.target\n",
    "\n",
    "digits_X = digits_data.data\n",
    "digits_Y = digits_data.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Function after change target values into binary(1-vs-all) values ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For :  0\n",
      "[[ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 2.  0.]\n",
      " ..., \n",
      " [ 8.  0.]\n",
      " [ 9.  0.]\n",
      " [ 8.  0.]]\n",
      "c        0.005000\n",
      "tol      0.100000\n",
      "AUROC    0.991199\n",
      "f1       0.988484\n",
      "Name: 16, dtype: float64\n",
      "For :  1\n",
      "[[ 0.  0.]\n",
      " [ 1.  1.]\n",
      " [ 2.  0.]\n",
      " ..., \n",
      " [ 8.  0.]\n",
      " [ 9.  0.]\n",
      " [ 8.  0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dninb/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c        0.005000\n",
      "tol      0.100000\n",
      "AUROC    0.991199\n",
      "f1       0.988484\n",
      "Name: 16, dtype: float64\n",
      "For :  2\n",
      "[[ 0.  0.]\n",
      " [ 1.  0.]\n",
      " [ 2.  1.]\n",
      " ..., \n",
      " [ 8.  0.]\n",
      " [ 9.  0.]\n",
      " [ 8.  0.]]\n",
      "c        5.000000e+00\n",
      "tol      1.000000e-07\n",
      "AUROC    9.939771e-01\n",
      "f1       9.913779e-01\n",
      "Name: 370, dtype: float64\n",
      "For :  3\n",
      "[[ 0.  0.]\n",
      " [ 1.  0.]\n",
      " [ 2.  0.]\n",
      " ..., \n",
      " [ 8.  0.]\n",
      " [ 9.  0.]\n",
      " [ 8.  0.]]\n",
      "c        5.000000e+00\n",
      "tol      1.000000e-07\n",
      "AUROC    9.939771e-01\n",
      "f1       9.913779e-01\n",
      "Name: 370, dtype: float64\n",
      "For :  4\n",
      "[[ 0.  0.]\n",
      " [ 1.  0.]\n",
      " [ 2.  0.]\n",
      " ..., \n",
      " [ 8.  0.]\n",
      " [ 9.  0.]\n",
      " [ 8.  0.]]\n",
      "c        5.000000e+00\n",
      "tol      1.000000e-07\n",
      "AUROC    9.939771e-01\n",
      "f1       9.913779e-01\n",
      "Name: 370, dtype: float64\n",
      "For :  5\n",
      "[[ 0.  0.]\n",
      " [ 1.  0.]\n",
      " [ 2.  0.]\n",
      " ..., \n",
      " [ 8.  0.]\n",
      " [ 9.  0.]\n",
      " [ 8.  0.]]\n",
      "c        5.000000e+00\n",
      "tol      1.000000e-07\n",
      "AUROC    9.939771e-01\n",
      "f1       9.913779e-01\n",
      "Name: 370, dtype: float64\n",
      "For :  6\n",
      "[[ 0.  0.]\n",
      " [ 1.  0.]\n",
      " [ 2.  0.]\n",
      " ..., \n",
      " [ 8.  0.]\n",
      " [ 9.  0.]\n",
      " [ 8.  0.]]\n",
      "c        5.000000e+00\n",
      "tol      1.000000e-07\n",
      "AUROC    9.939771e-01\n",
      "f1       9.913779e-01\n",
      "Name: 370, dtype: float64\n",
      "For :  7\n",
      "[[ 0.  0.]\n",
      " [ 1.  0.]\n",
      " [ 2.  0.]\n",
      " ..., \n",
      " [ 8.  0.]\n",
      " [ 9.  0.]\n",
      " [ 8.  0.]]\n",
      "c        5.000000e+00\n",
      "tol      1.000000e-07\n",
      "AUROC    9.939771e-01\n",
      "f1       9.913779e-01\n",
      "Name: 370, dtype: float64\n",
      "For :  8\n",
      "[[ 0.  0.]\n",
      " [ 1.  0.]\n",
      " [ 2.  0.]\n",
      " ..., \n",
      " [ 8.  1.]\n",
      " [ 9.  0.]\n",
      " [ 8.  1.]]\n",
      "c        5.000000e+00\n",
      "tol      1.000000e-07\n",
      "AUROC    9.939771e-01\n",
      "f1       9.913779e-01\n",
      "Name: 370, dtype: float64\n",
      "For :  9\n",
      "[[ 0.  0.]\n",
      " [ 1.  0.]\n",
      " [ 2.  0.]\n",
      " ..., \n",
      " [ 8.  0.]\n",
      " [ 9.  1.]\n",
      " [ 8.  0.]]\n",
      "c        5.000000e+00\n",
      "tol      1.000000e-07\n",
      "AUROC    9.939771e-01\n",
      "f1       9.913779e-01\n",
      "Name: 370, dtype: float64\n",
      "Duration 90.28 sec\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "# Dataset selection\n",
    "data_X = iris_X\n",
    "data_Y = iris_Y\n",
    "\n",
    "data_X = digits_X\n",
    "data_Y = digits_Y\n",
    "\n",
    "# Find distinct values in the target\n",
    "for tgt_y in list(set(data_Y)):\n",
    "    # Init the new target values\n",
    "    print('For : ', tgt_y)\n",
    "    #print(data_Y)\n",
    "    data_Y_bin = pd.Series(np.zeros(len(data_Y)))\n",
    "    data_Y_bin[data_Y == tgt_y] = 1\n",
    "    data_Y_bin[data_Y != tgt_y] = 0\n",
    "    print(np.vstack((data_Y, data_Y_bin)).T)\n",
    "    \n",
    "    kf = StratifiedKFold(data_Y_bin, n_folds = n_fold)\n",
    "    clf_LogisticLR(kf, data_X, data_Y_bin, lr_param, lr_results)\n",
    "    \n",
    "print('Duration %.2f sec' %(time.time() - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Iris] Change target values into binary(one-vs-all) values ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_LogisticLR(kf, data_X, data_Y_bin, lr_param, lr_results):\n",
    "    # Logistic linear regression Model\n",
    "    for c, tol in itertools.product(lr_param['C'], lr_param['tol']):\n",
    "        clf_LR = linear_model.LogisticRegression(C=c, penalty='l2', tol=tol)\n",
    "        cv_results = pd.DataFrame(np.empty((0,2), float), columns=['AUROC', 'f1'])\n",
    "        \n",
    "        for train, test in kf:\n",
    "            clf_LR.fit(data_X[train, :], data_Y_bin[train])\n",
    "            \n",
    "            trn_predY = clf_LR.predict(data_X[test, :])\n",
    "            #print(np.vstack((data_Y_bin[test],trn_predY)).T)\n",
    "            f1_score = metrics.f1_score(data_Y_bin[test], trn_predY)\n",
    "            auroc_score = metrics.roc_auc_score(data_Y_bin[test], trn_predY)\n",
    "            \n",
    "            cv_results.loc[len(cv_results)] = [auroc_score, f1_score] \n",
    "    #         scores_roc  = cross_validation.cross_val_score(clf_LR, data_X, data_Y_bin, cv=n_fold, scoring='roc_auc')\n",
    "    #         scores_prec = cross_validation.cross_val_score(clf_LR, data_X, data_Y_bin, cv=n_fold, scoring='f1')\n",
    "    #         scores_rec  = cross_validation.cross_val_score(clf_LR, data_X, data_Y_bin, cv=n_fold, scoring='recall')\n",
    "    #         scores_acc  = cross_validation.cross_val_score(clf_LR, data_X, data_Y_bin, cv=n_fold, scoring='accuracy')\n",
    "            #print(c, tol, f1_score)\n",
    "        \n",
    "        avg_cv_results = cv_results.mean(axis=0)\n",
    "        #print(cv_results)\n",
    "        #print(avg_cv_results['AUROC'])\n",
    "        lr_results.loc[len(lr_results)] = [c, tol, avg_cv_results['AUROC'], avg_cv_results['f1']]\n",
    "        del cv_results, avg_cv_results\n",
    "        #print(lr_results)\n",
    "    # Select the best parameter    \n",
    "    best_param_idx = lr_results.idxmax()['f1']\n",
    "    print(lr_results.loc[best_param_idx, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(lr_results.iloc[[lr_results.idxmax()['AUROC']]])\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "\n",
    "aa = []\n",
    "aa.ins\n",
    "\n",
    "metrics.roc_auc_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
