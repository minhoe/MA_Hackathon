{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn import  metrics, grid_search, linear_model, svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "Training_file = './Dataset/train_ZoGVYWq.csv'\n",
    "Test_file     = './Dataset/test_66516Ee.csv'\n",
    "\n",
    "Training_dtype = {'id':np.str, 'perc_premium_paid_by_cash_credit':np.float32, \n",
    "'age_in_days':np.float32, \n",
    "'Income':np.float32,\n",
    "'Count_3-6_months_late':np.float32, \n",
    "'Count_6-12_months_late':np.float32,\n",
    "'Count_more_than_12_months_late':np.float32, \n",
    "'application_underwriting_score':np.float32,\n",
    "'no_of_premiums_paid':np.float32, \n",
    "'sourcing_channel':np.str, \n",
    "'residence_area_type':np.str,\n",
    "'premium':np.int, \n",
    "'renewal':np.int}\n",
    "\n",
    "Test_dtype = {'id':np.str, 'perc_premium_paid_by_cash_credit':np.float32, \n",
    "'age_in_days':np.float32, \n",
    "'Income':np.float32,\n",
    "'Count_3-6_months_late':np.float32, \n",
    "'Count_6-12_months_late':np.float32,\n",
    "'Count_more_than_12_months_late':np.float32, \n",
    "'application_underwriting_score':np.float32,\n",
    "'no_of_premiums_paid':np.float32, \n",
    "'sourcing_channel':np.str, \n",
    "'residence_area_type':np.str,\n",
    "'premium':np.int}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Loading Dataset - Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "trn_origin = pd.read_csv(Training_file, dtype=Training_dtype, na_values='')\n",
    "tst_origin = pd.read_csv(Test_file, dtype=Test_dtype, na_values='')\n",
    "\n",
    "display(trn_origin.head())\n",
    "display(tst_origin.head())\n",
    "\n",
    "#Check the shape of each dataset\n",
    "print(trn_origin.shape)\n",
    "print(tst_origin.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2) Check the descriptive statistics for each dataset\n",
    "- We can see that some columns have 'missing' values in it as counts of each column are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(trn_origin.describe())\n",
    "display(tst_origin.describe())\n",
    "\n",
    "# age_in_days, Income, Count_3-6_months_late, Count_6-12_months_late\tCount_more_than_12_months_late\tapplication_underwriting_score\tno_of_premiums_paid\tpremium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-0) Split X and Y dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_origin_X = trn_origin.loc[:,trn_origin.columns != 'renewal'].copy()\n",
    "trn_origin_Y = trn_origin.loc[:,'renewal'].copy()\n",
    "\n",
    "tst_origin_X = tst_origin.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1) Imputating Missing values\n",
    "- We can figure out columns containing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the missing values\n",
    "display(trn_origin_X.isnull().sum())\n",
    "display(tst_origin_X.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation Strategy 1 : Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# From .isnull().sum()\n",
    "na_in_cols = ['Count_3-6_months_late', 'Count_6-12_months_late', \n",
    "            'Count_more_than_12_months_late', 'application_underwriting_score']\n",
    "\n",
    "trn_imputed_X = trn_origin_X.copy()\n",
    "tst_imputed_X = tst_origin_X.copy()\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(trn_imputed_X[na_in_cols])\n",
    "\n",
    "trn_imputed_X[na_in_cols] = imp.transform(trn_imputed_X[na_in_cols])\n",
    "tst_imputed_X[na_in_cols] = imp.transform(tst_imputed_X[na_in_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation Strategy 2 : K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the missing values AGAIN\n",
    "display(trn_imputed_X.isnull().sum())\n",
    "display(tst_imputed_X.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2) Convert string values into dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_cols = ['sourcing_channel', 'residence_area_type']\n",
    "\n",
    "# Concatenate trn and test X dataset\n",
    "n_row_trn, ncol_trn = trn_imputed_X.shape\n",
    "n_row_tst, ncol_tst = tst_imputed_X.shape\n",
    "\n",
    "agg_data_X = pd.concat([trn_imputed_X, tst_imputed_X], axis=0)\n",
    "\n",
    "for cat_col in cat_cols:\n",
    "    print(' Convert string values from col : ', cat_col)\n",
    "\n",
    "    just_dummy = pd.get_dummies(agg_data_X[cat_col], prefix=cat_col)\n",
    "    #print(just_dummy)\n",
    "    \n",
    "    # Concatenate dummy columns into dataset\n",
    "    agg_data_X = pd.concat([agg_data_X, just_dummy], axis=1)\n",
    "    # Drop the origin column\n",
    "    agg_data_X.drop(cat_col, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Split trn and test X dataset\n",
    "trn_imputed_dum_X = agg_data_X.iloc[0:n_row_trn, :].copy()\n",
    "tst_imputed_dum_X = agg_data_X.iloc[n_row_trn:, :].copy()\n",
    "\n",
    "print(trn_imputed_dum_X.shape)\n",
    "print(tst_imputed_dum_X.shape)\n",
    "\n",
    "    #display(agg_data_X)\n",
    "#     label_encoder = LabelEncoder()\n",
    "#     onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "#     trn_col_arr = trn_imputed[cat_col]\n",
    "#     tst_col_arr = tst_imputed[cat_col]\n",
    "    \n",
    "#     ## Str to Integer encoding\n",
    "#     label_encoder.fit(trn_col_arr)\n",
    "#     trn_int_encoded = label_encoder.transform(trn_col_arr)\n",
    "#     tst_int_encoded = label_encoder.transform(tst_col_arr)\n",
    "#     #print(integer_encoded)\n",
    "\n",
    "#     ## Integer to Binary encoding\n",
    "#     trn_int_encoded = trn_int_encoded.reshape(len(trn_int_encoded), 1)\n",
    "#     tst_int_encoded = tst_int_encoded.reshape(len(tst_int_encoded), 1)\n",
    "#     onehot_encoder.fit(trn_int_encoded)\n",
    "#     trn_onehot_encoded = onehot_encoder.transform(trn_int_encoded)\n",
    "#     tst_onehot_encoded = onehot_encoder.transform(tst_int_encoded)\n",
    "    \n",
    "#     print(trn_onehot_encoded)\n",
    "#     print(tst_onehot_encoded)\n",
    "    \n",
    "    ## Merge to the dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3) Data standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_std = ['age_in_days', 'Income', 'Count_3-6_months_late', \n",
    "                'Count_6-12_months_late', 'Count_more_than_12_months_late', 'application_underwriting_score',\n",
    "                'no_of_premiums_paid', 'premium']\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(trn_imputed_dum_X[cols_for_std])\n",
    "trn_imputed_dum_X[cols_for_std] = scaler.transform(trn_imputed_dum_X[cols_for_std])\n",
    "tst_imputed_dum_X[cols_for_std] = scaler.transform(tst_imputed_dum_X[cols_for_std])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 10\n",
    "kf = StratifiedKFold(trn_origin_Y, n_folds = n_fold)\n",
    "scoring = {'AUC': 'roc_auc', 'F1': 'f1', 'Prec':'precision', 'Rec':'recall'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1) Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "lr_param = {'C':[0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.5, 1, 5, 10],\n",
    "           'tol' : [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10]}\n",
    "\n",
    "lr_param = {'C':[0.001,  10],\n",
    "           'tol' : [1e-7, 5, 10]}\n",
    "\n",
    "lr_results = pd.DataFrame(np.empty((0,4), float), columns=['c', 'tol', 'AUROC', 'f1'])\n",
    "\n",
    "\n",
    "def clf_LogisticLR(kf):\n",
    "    clf_LR = linear_model.LogisticRegression()\n",
    "    \n",
    "    for trn_idx, val_idx in kf:\n",
    "        clf = GridSearchCV(clf_LR, lr_param, n_jobs=8, scoring=scoring)\n",
    "        clf.fit(trn_imputed_dum_X.loc[trn_idx,:], trn_origin_Y.loc[trn_idx], refit='roc_auc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3-x) DO PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_LogisticLR(kf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3)",
   "language": "python",
   "name": "conda_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
