{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn import grid_search, linear_model, svm\n",
    "\n",
    "#\n",
    "dum_cols = ['T1_V4', 'T1_V5', 'T1_V6', 'T1_V7', 'T1_V8', 'T1_V9', \n",
    "            'T1_V11', 'T1_V12', 'T1_V15', 'T1_V16', 'T1_V17', \n",
    "            'T2_V3', 'T2_V5', 'T2_V11', 'T2_V12', 'T2_V13']\n",
    "dum_cols_names = ['Dum_'+a for a in dum_cols]\n",
    "\n",
    "n_fold = 10\n",
    "\n",
    "\n",
    "def gini(list_of_values):\n",
    "  sorted_list = sorted(list(list_of_values))\n",
    "  height, area = 0, 0\n",
    "  for value in sorted_list:\n",
    "    height += value\n",
    "    area += height - value / 2.\n",
    "  fair_area = height * len(list_of_values) / 2\n",
    "  return (fair_area - area) / fair_area\n",
    "  \n",
    "def normalized_gini(y_pred, y):\n",
    "    normalized_gini = gini(y_pred)/gini(y)\n",
    "    return normalized_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting categorical column T1_V4. Number of distinct items : 8\n",
      " - Converted : 7 dummy columns are generated.\n",
      "Converting categorical column T1_V5. Number of distinct items : 10\n",
      " - Converted : 9 dummy columns are generated.\n",
      "Converting categorical column T1_V6. Number of distinct items : 2\n",
      " - Converted : 1 dummy columns are generated.\n",
      "Converting categorical column T1_V7. Number of distinct items : 4\n",
      " - Converted : 3 dummy columns are generated.\n",
      "Converting categorical column T1_V8. Number of distinct items : 4\n",
      " - Converted : 3 dummy columns are generated.\n",
      "Converting categorical column T1_V9. Number of distinct items : 6\n",
      " - Converted : 5 dummy columns are generated.\n",
      "Converting categorical column T1_V11. Number of distinct items : 12\n",
      " - Converted : 11 dummy columns are generated.\n",
      "Converting categorical column T1_V12. Number of distinct items : 4\n",
      " - Converted : 3 dummy columns are generated.\n",
      "Converting categorical column T1_V15. Number of distinct items : 8\n",
      " - Converted : 7 dummy columns are generated.\n",
      "Converting categorical column T1_V16. Number of distinct items : 18\n",
      " - Converted : 17 dummy columns are generated.\n",
      "Converting categorical column T1_V17. Number of distinct items : 2\n",
      " - Converted : 1 dummy columns are generated.\n",
      "Converting categorical column T2_V3. Number of distinct items : 2\n",
      " - Converted : 1 dummy columns are generated.\n",
      "Converting categorical column T2_V5. Number of distinct items : 6\n",
      " - Converted : 5 dummy columns are generated.\n",
      "Converting categorical column T2_V11. Number of distinct items : 2\n",
      " - Converted : 1 dummy columns are generated.\n",
      "Converting categorical column T2_V12. Number of distinct items : 2\n",
      " - Converted : 1 dummy columns are generated.\n",
      "Converting categorical column T2_V13. Number of distinct items : 5\n",
      " - Converted : 4 dummy columns are generated.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load dataset\n",
    "trn_data = pd.read_csv('../Kaggle/train.csv', sep=',')\n",
    "trn_data_X_old = trn_data.loc[:,trn_data.columns != 'Hazard']\n",
    "trn_data_Y = trn_data.loc[:,'Hazard']\n",
    "n_row_trn, ncol_trn = trn_data_X_old.shape\n",
    "\n",
    "tst_data_X_old = pd.read_csv('../Kaggle/test.csv', sep=',')\n",
    "#tst_data.head()\n",
    "n_row_tst, n_col_tst = tst_data_X_old.shape\n",
    "\n",
    "\n",
    "## Convert Categorical variables into dummies\n",
    "\n",
    "# Concatenate trn and test X dataset\n",
    "agg_data_X = pd.concat([trn_data_X_old, tst_data_X_old], axis=0)\n",
    "#print(trn_data_X.shape, tst_data_X.shape, agg_data_X.shape)\n",
    "\n",
    "for cid in range(len(dum_cols)):\n",
    "    print('Converting categorical column %s. Number of distinct items : %d' \\\n",
    "          %(dum_cols[cid], len(agg_data_X[dum_cols[cid]].value_counts())))\n",
    "    just_dummy = pd.get_dummies(agg_data_X[dum_cols[cid]], prefix=dum_cols_names[cid])\n",
    "    # Drop the last dummy column\n",
    "    just_dummy.drop(just_dummy.columns[[just_dummy.shape[1]-1]], axis=1, inplace=True)\n",
    "    print(' - Converted : %d dummy columns are generated.' %(just_dummy.shape[1]))\n",
    "    # Concatenate dummy columns into dataset\n",
    "    agg_data_X = pd.concat([agg_data_X, just_dummy], axis=1)\n",
    "    # Drop the origin column\n",
    "    agg_data_X.drop(dum_cols[cid], axis=1, inplace=True)\n",
    "\n",
    "# Split trn and test X dataset\n",
    "trn_data_X = agg_data_X.iloc[0:n_row_trn, :]\n",
    "tst_data_X = agg_data_X.iloc[n_row_trn:, :]\n",
    "#print(trn_data_X_old.shape, trn_data_X.shape, tst_data_X_old.shape, tst_data_X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.000010 | RSS: 14.6840  | Variance Score: 0.0918 | NormGini:  0.3454 \n",
      "Alpha: 0.000050 | RSS: 14.6827  | Variance Score: 0.0918 | NormGini:  0.3451 \n",
      "Alpha: 0.000090 | RSS: 14.6819  | Variance Score: 0.0919 | NormGini:  0.3448 \n",
      "Alpha: 0.000100 | RSS: 14.6817  | Variance Score: 0.0919 | NormGini:  0.3448 \n",
      "Alpha: 0.000200 | RSS: 14.6806  | Variance Score: 0.0920 | NormGini:  0.3440 \n",
      "Alpha: 0.000300 | RSS: 14.6801  | Variance Score: 0.0920 | NormGini:  0.3434 \n",
      "Alpha: 0.000500 | RSS: 14.6798  | Variance Score: 0.0920 | NormGini:  0.3422 \n",
      "Alpha: 0.000700 | RSS: 14.6795  | Variance Score: 0.0920 | NormGini:  0.3410 \n",
      "Alpha: 0.000900 | RSS: 14.6795  | Variance Score: 0.0920 | NormGini:  0.3400 \n",
      "Alpha: 0.000100 | RSS: 14.6817  | Variance Score: 0.0919 | NormGini:  0.3448 \n",
      "Alpha: 0.001000 | RSS: 14.6797  | Variance Score: 0.0920 | NormGini:  0.3395 \n",
      "Alpha: 0.001500 | RSS: 14.6815  | Variance Score: 0.0919 | NormGini:  0.3371 \n",
      "Alpha: 0.003000 | RSS: 14.6903  | Variance Score: 0.0914 | NormGini:  0.3309 \n",
      "Alpha: 0.004000 | RSS: 14.6974  | Variance Score: 0.0910 | NormGini:  0.3273 \n",
      "Alpha: 0.005000 | RSS: 14.7050  | Variance Score: 0.0905 | NormGini:  0.3241 \n",
      "Alpha: 0.006000 | RSS: 14.7123  | Variance Score: 0.0901 | NormGini:  0.3211 \n",
      "Alpha: 0.007000 | RSS: 14.7188  | Variance Score: 0.0897 | NormGini:  0.3181 \n",
      "Alpha: 0.008000 | RSS: 14.7256  | Variance Score: 0.0892 | NormGini:  0.3153 \n",
      "Alpha: 0.009000 | RSS: 14.7334  | Variance Score: 0.0888 | NormGini:  0.3126 \n",
      "Alpha: 0.010000 | RSS: 14.7418  | Variance Score: 0.0882 | NormGini:  0.3099 \n",
      "Alpha: 0.050000 | RSS: 15.0603  | Variance Score: 0.0685 | NormGini:  0.2405 \n",
      "Alpha: 0.100000 | RSS: 15.4707  | Variance Score: 0.0431 | NormGini:  0.1912 \n",
      "Alpha: 0.150000 | RSS: 15.6627  | Variance Score: 0.0312 | NormGini:  0.1683 \n",
      "Duration 59385.93 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dninb/anaconda/lib/python3.4/site-packages/sklearn/linear_model/coordinate_descent.py:444: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Separating Trn dataset into 10 fold datasets\n",
    "trn_data_Y_idx = pd.Series(np.zeros(n_row_trn))\n",
    "\n",
    "trn_data_Y_idx[trn_data_Y == 1] = 1\n",
    "trn_data_Y_idx[(trn_data_Y > 1) & (trn_data_Y <= 5)] = 5\n",
    "trn_data_Y_idx[(trn_data_Y > 6) & (trn_data_Y <= 10)] = 10\n",
    "trn_data_Y_idx[(trn_data_Y > 10) & (trn_data_Y <= 20)] = 20\n",
    "trn_data_Y_idx[(trn_data_Y > 20) & (trn_data_Y <= 30)] = 30\n",
    "\n",
    "kf = StratifiedKFold(trn_data_Y_idx, n_folds = n_fold)\n",
    "\n",
    "t1 = time.time()\n",
    "lasso_reg(kf, trn_data_X, trn_data_Y, n_fold)\n",
    "print('Duration %.2f sec' %(time.time() - t1))\n",
    "\n",
    "#trn_data.loc[3,'Id']\n",
    "#trn_data[1:10]['Hazard']\n",
    "#trn_data.loc[1:10,'Hazard':]\n",
    "#trn_data.iloc[3:10,4:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "# lss = ['a', 'b', 'c', 'd']\n",
    "# lst = [a+'_1' for a in lss]\n",
    "# print(lst)\n",
    "\n",
    "# print(lss[0], lss[[1,2]])\n",
    "# print(agg_data_X['T1_V4'].value_counts())\n",
    "# print(len(agg_data_X['T1_V4'].value_counts()))\n",
    "\n",
    "\n",
    "# lss.index('a')\n",
    "\n",
    "param_results = pd.DataFrame(np.empty((0,4), float), columns=['Alpha', 'RSS', 'VarScore', 'NormGini'])\n",
    "param_results.loc[len(param_results)] = [0.000001] + ['a',2,3]\n",
    "\n",
    "a =[1,2,3]\n",
    "\n",
    "print([3] + [ 3,2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso linear regression Model\n",
    "def lasso_reg(kf, trn_data_X, trn_data_Y, n_fold):\n",
    "    parameters = {'alpha':[0.00001, 0.00005, 0.00009, 0.0001, 0.0002, 0.0003, 0.0005, 0.0007, 0.0009, 0.0001, 0.001, 0.0015, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.05, 0.1, 0.15]}\n",
    "    param_results = pd.DataFrame(np.empty((0,4), float), columns=['Alpha', 'RSS', 'VarScore', 'NormGini'])\n",
    "    \n",
    "    # Training Predictive models\n",
    "    for alpha_item in parameters['alpha']:\n",
    "        clf = linear_model.Lasso(alpha = alpha_item, max_iter=2000)\n",
    "        cv_out = np.empty((0,3), float)\n",
    "        val_idx = 1\n",
    "        for train, test in kf:\n",
    "            #print('Fold %d. Training : Validation = %d : %d' %(val_idx, len(train), len(test)))\n",
    "            clf.fit(trn_data_X.loc[train, :], trn_data_Y.loc[train])\n",
    "            trn_data_predY = clf.predict(trn_data_X.loc[test, :])\n",
    "            # mean square error\n",
    "            \n",
    "            #print(trn_data_predY.shape, trn_data_Y.loc[test].shape)\n",
    "            rss                = np.mean((trn_data_predY - trn_data_Y.loc[test]) ** 2)\n",
    "            varscore = clf.score(trn_data_X.loc[test, :],  trn_data_Y.loc[test])\n",
    "            norm_gini =   normalized_gini(trn_data_predY,  trn_data_Y.loc[test])\n",
    "            # Explained variance score: 1 is perfect prediction\n",
    "            #print(\"RSS: %.2f  | Variance Score: %.2f | NormGini:  %.2f \" %(rss, varscore, norm_gini))\n",
    "            \n",
    "            cv_out = np.append(cv_out, np.array([[rss, varscore, norm_gini]]), axis=0)\n",
    "            val_idx = val_idx + 1\n",
    "        \n",
    "        avg_cv_out = cv_out.mean(axis=0)\n",
    "        print('Alpha: %f | RSS: %.4f  | Variance Score: %.4f | NormGini:  %.4f '\\\n",
    "              %(alpha_item, avg_cv_out[0], avg_cv_out[1], avg_cv_out[2]))\n",
    "        #print(np.insert(avg_cv_out, 0, alpha_item), [alpha_item], [alpha_item] + avg_cv_out, len([alpha_item] + avg_cv_out), param_results.shape)\n",
    "        param_results.loc[len(param_results)] = np.insert(avg_cv_out, 0, alpha_item)\n",
    "    \n",
    "    best_param = param_results.idxmin()['NormGini']\n",
    "    \n",
    "    # Prediction\n",
    "    \n",
    "#     parameters = {'alpha':[0.01, 0.5]}\n",
    "#     print('here?')\n",
    "#     lsm = linear_model.Lasso()\n",
    "#     clf = grid_search.GridSearchCV(lsm, parameters, cv=n_fold, n_jobs=2)\n",
    "#     clf.fit(trn_data_X, trn_data_Y)\n",
    "#     print(clf.best_params_, clf.best_score_, clf.best_estimator_)\n",
    "#     print(clf.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[ 2.5  3.5  4.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  2.5,  3.5,  4.5])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "arr = np.empty((0,3), int)\n",
    "arr = np.append(arr, np.array([[1,2,3]]), axis=0)\n",
    "arr = np.append(arr, np.array([[4,5,6]]), axis=0)\n",
    "print(arr)\n",
    "print(arr.mean(axis=0))\n",
    "\n",
    "np.insert(arr.mean(axis=0), 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Alpha  RSS  VarScore\n",
      "0      1    2         3\n",
      "1  32423    2         3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_results = pd.DataFrame(np.empty((0,3), float), columns=['Alpha', 'RSS', 'VarScore'])\n",
    "param_results.loc[len(param_results)] = [1,2,3]\n",
    "param_results.loc[len(param_results)] = [32423,2,3]\n",
    "print(param_results)\n",
    "\n",
    "param_results.idxmin()['RSS']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
